{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jWfzNlZXoUa"
      },
      "source": [
        "# Fine Tune GPT-2 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzL2cimNXoUb"
      },
      "source": [
        "Open Questions:\n",
        "- Is it useful to add \\<bot> statement as preparing step? -> yesss\n",
        "- Should one batch, one dialog?\n",
        "- Currently the dialogs are mixed, so only question and answer is paired right now\n",
        "    - How to fix?\n",
        "    - The batches?\n",
        "- Removing Bot answers?<br>\n",
        "    From:<br>\n",
        "    '<start> Create me a unique interactive story to calm with the topic: Ocean. <bot>:Ah, the ocean... <end>',<br>\n",
        "    \"<start> Ah, the ocean. Such a ... <end>\",<br>\n",
        "    \"<start> Yes, I can feel it...'<br>\n",
        "    <br>\n",
        "    to:<br>\n",
        "    '<start> Create me a unique interactive story to calm with the topic: Ocean. <bot>:Ah, the ocean... <end>',<br>\n",
        "    \"<start> Yes, I can feel it...'<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxvjNZgAXoUc"
      },
      "source": [
        "\n",
        "1. **Dialog-based Approach:**\n",
        "   - **One Batch, One Dialog:**\n",
        "     - Treat each dialog as a separate training example. This allows the model to learn the context and flow of individual conversations.\n",
        "     - Helps the model focus on capturing the nuances of each conversation independently.\n",
        "     - Useful if your storytelling involves short, distinct dialogs.\n",
        "\n",
        "   - **Inclusion of the Past:**\n",
        "     - You can include the past history within each dialog example. Concatenate the previous turns in the conversation to provide context.\n",
        "     - This helps the model understand the context and continuity of the ongoing dialog.\n",
        "     - Be mindful of the token limit, as GPT-2 has a maximum token limit, and longer sequences might get truncated.\n",
        "\n",
        "2. **Memory and Context:**\n",
        "   - GPT-2 has a limited context window due to its fixed input size. If the conversations are long, you might lose relevant information.\n",
        "   - Consider balancing the length of your input sequences to ensure the model can capture essential details.\n",
        "\n",
        "3. **Dynamic Context Window:**\n",
        "   - Instead of a fixed history length, you could use a sliding window approach.\n",
        "   - Maintain a dynamic context window that moves along the conversation, incorporating the most recent interactions.\n",
        "\n",
        "4. **Experiment and Evaluate:**\n",
        "   - It's often beneficial to experiment with different approaches to see what works best for your specific use case.\n",
        "   - Conduct thorough evaluations using validation data to ensure the model is learning effectively and providing desired responses.\n",
        "\n",
        "5. **Training Strategies:**\n",
        "   - Experiment with hyperparameters like learning rate, batch size, and the number of training epochs to fine-tune the model effectively.\n",
        "   - Monitor the model's performance on both training and validation sets.\n",
        "\n",
        "Preprocess: handling tokenization, special tokens, and managing the context window."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi2RT8J7XoUc"
      },
      "source": [
        "Hint: Use the dialogs.txt file to train the model on google colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhd3wPF2XoUc"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOu4dG9sXoUc",
        "outputId": "914505d6-83ea-41c4-c99d-33fd29b62a10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "697uWwk6XoUd"
      },
      "outputs": [],
      "source": [
        "#!python -m pip install torch\n",
        "#!python -m pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MrZaWIOKXoUd"
      },
      "outputs": [],
      "source": [
        "#from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "\n",
        "import json\n",
        "\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.optim import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbGx0tsncS8S",
        "outputId": "5b823b30-f269-4863-f1f3-3b72e087fcf9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['.config', 'dialogs.txt', 'sample_data']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(\"./\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgi402IpXoUd"
      },
      "source": [
        "### Load and Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VFiQ05wnXoUd"
      },
      "outputs": [],
      "source": [
        "MODEL_PATH = \"./model/model.pth\"\n",
        "MODEL_WEIGHT_PATH = \"./model/model_weights.pth\"\n",
        "ONNX_PATH = \"./model/model.onnx\"\n",
        "MAX_LENGTH = 1024\n",
        "# \".pt\", \".pth\", \".pkl\", or \".h5\"\n",
        "\n",
        "class Dialog_Data(Dataset):\n",
        "\n",
        "    def __init__(self, tokenizer, data_dir_path=\"./data\", read_one_file=False):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data_dir_path = data_dir_path\n",
        "        self.read_data(data_dir_path, read_one_file)\n",
        "\n",
        "    def read_data(self, data_dir_path, read_one_file, should_save_as_one_file=True):\n",
        "        data = []\n",
        "        conversations = []\n",
        "        if read_one_file:\n",
        "            with open(\"./dialogs.txt\", \"r\", encoding=\"latin1\") as f:\n",
        "                raw = f.read()\n",
        "            for dialog in raw.split(\"#/\"):\n",
        "                cur_conversation = []\n",
        "                for sentence in dialog.split(\";\"):\n",
        "                    data += [sentence]\n",
        "                    cur_conversation += [sentence]\n",
        "                conversations += [(cur_conversation)]\n",
        "        else:\n",
        "            for dialog in os.listdir(self.data_dir_path):\n",
        "                    with open(f\"{self.data_dir_path}/{dialog}\", \"r\") as f:\n",
        "                        cur_conversation = []\n",
        "                        for idx, line in enumerate(f.read().split(\"\\n\")):\n",
        "                            content = \":\".join(line.split(\":\")[1:]).strip()\n",
        "                            if len(content) > 0:\n",
        "                                if idx == 0:\n",
        "                                    data += [f\"Create me a unique interactive story to calm with the topic: {content}\"]\n",
        "                                    cur_conversation += [f\"Create me a unique interactive story to calm with the topic: {content}\"]\n",
        "                                else:\n",
        "                                    data += [content]\n",
        "                                    cur_conversation += [content]\n",
        "                    conversations += [(cur_conversation)]\n",
        "            if should_save_as_one_file:\n",
        "                save_data = \"\"\n",
        "                for idx_1, dialog in enumerate(conversations):\n",
        "                    if idx_1 > 0:\n",
        "                        save_data += \"#/\"\n",
        "\n",
        "                    for idx_2, elem in enumerate(dialog):\n",
        "                        if idx_2 == 0:\n",
        "                            save_data += f\"{elem}\"\n",
        "                        else:\n",
        "                            save_data += f\";{elem}\"\n",
        "                    with open(\"./dialogs.txt\", \"w\") as f:\n",
        "                        f.write(save_data)\n",
        "\n",
        "        # add markers:\n",
        "        for idx in range(0, len(data)-1):    # last elem should be skipped\n",
        "                data[idx] = f\"<start> {data[idx]} <bot>:{data[idx+1]} <end>\"\n",
        "\n",
        "        self.conversations = conversations\n",
        "        self.data = data[:-1]    # [:3000]\n",
        "        self.encoded_data = self.tokenizer(self.data, truncation=True, return_tensors=\"pt\", max_length=MAX_LENGTH, padding=\"max_length\", padding_side=\"right\") # max_length=40, padding=\"max_length\"\n",
        "\n",
        "        self.input_ids = self.encoded_data['input_ids']\n",
        "        self.attention_mask = self.encoded_data['attention_mask']\n",
        "\n",
        "        # set max len of the input and mask -> for padding the data\n",
        "        # MAX_INPUT_LEN = 0\n",
        "        # for cur_i in self.input_ids:\n",
        "        #     if len(cur_i) > MAX_INPUT_LEN:\n",
        "        #         MAX_INPUT_LEN = len(cur_i)\n",
        "        # self.MAX_INPUT_LEN = MAX_INPUT_LEN\n",
        "\n",
        "        # MAX_ATTENTION_LEN = 0\n",
        "        # for cur_i in self.attention_mask:\n",
        "        #     if len(cur_i) > MAX_ATTENTION_LEN:\n",
        "        #         MAX_ATTENTION_LEN = len(cur_i)\n",
        "        # self.MAX_ATTENTION_LEN = MAX_ATTENTION_LEN\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # transform to tensor\n",
        "        # input_ = torch.Tensor(self.input_ids[idx])\n",
        "        # attention_mask_ = torch.Tensor(self.attention_mask[idx])\n",
        "\n",
        "        # add padding, that every batch have the same size\n",
        "        # padding_input = self.MAX_INPUT_LEN - len(input_)\n",
        "        # padding_attention_mask = self.MAX_ATTENTION_LEN - len(attention_mask_)\n",
        "        # if padding_input > 0:\n",
        "        #     input_ = torch.cat((input_, torch.zeros(padding_input)))\n",
        "        # if padding_attention_mask > 0:\n",
        "        #     attention_mask_ = torch.cat((attention_mask_, torch.zeros(padding_attention_mask)))\n",
        "        return (self.input_ids[idx], self.attention_mask[idx])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ONd2dOaXoUe",
        "outputId": "4b599301-73e7-4139-c385-5ac72bded5b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.add_special_tokens({  \"pad_token\": \"<pad>\",\n",
        "                                \"bos_token\": \"<start>\",\n",
        "                                \"eos_token\": \"<end>\"})\n",
        "tokenizer.add_tokens([\"<bot>:\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r2qOzeAAXoUe"
      },
      "outputs": [],
      "source": [
        "data = Dialog_Data(tokenizer=tokenizer, read_one_file=True)\n",
        "data = DataLoader(data, batch_size=64)\n",
        "#  make the batch-size bigger, 64, 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9Gto4PnaHK_",
        "outputId": "331ae506-d101-40e7-dd9f-dda9835e323d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<start> Create me a unique interactive story to calm with the topic: Ocean. <bot>:Ah, the ocean. Such a vast, serene place. Close your eyes for a moment and take a deep breath, imagining the salty scent of the sea. Now, picture yourself standing on a beautiful sandy beach, the warmth of the golden sun touching your skin. Can you feel it? <end> \n",
            "\n",
            "<start> Yes, I can feel it. It's so inviting and peaceful. <bot>:As you stand there, listen closely. Can you hear the gentle rhythm of the waves washing ashore? It's as if the ocean is whispering a calming melody just for you. Take a moment to tune in and let these soothing sounds wash away any stress or worries you may have. <end> \n",
            "\n",
            "<start> I am focusing on the sounds of the waves, feeling them melting away my tension. It's like a lullaby for the soul. <bot>:Now, let your imagination guide you towards the water's edge. As you approach, notice how the sand feels beneath your feet - soft and welcoming, with each grain embracing your toes. With each step, feel the water softly brush against your feet, refreshing and revitalizing. <end> \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# check the data\n",
        "[print(i, \"\\n\") for i in data.dataset.data[:3]];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9Ns1dy6adDf",
        "outputId": "ca51ef37-681d-4bfb-ef5c-5b04fb2ff226"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29997"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data.dataset.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RPbFzFnhXoUe"
      },
      "outputs": [],
      "source": [
        "# # Test saved dialogs in one file\n",
        "# counter = 0\n",
        "# with open(\"./dialogs.txt\", \"r\") as f:\n",
        "#     dialogs = f.read()\n",
        "# print(f\"Dialogs amount: {len(os.listdir('./data'))}\")\n",
        "# print(f\"In one file dialogs amount: {len(dialogs.split('#'))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAGX1Qq8XoUe",
        "outputId": "fc60e9c0-0007-4691-e5d6-4d1c8d1ea0b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[50258, 13610,   502,  ..., 50257, 50257, 50257],\n",
            "        [50258,  3363,    11,  ..., 50257, 50257, 50257],\n",
            "        [50258,   314,   716,  ..., 50257, 50257, 50257],\n",
            "        ...,\n",
            "        [50258,  1081,   345,  ..., 50257, 50257, 50257],\n",
            "        [50258,  2295,  1671,  ..., 50257, 50257, 50257],\n",
            "        [50258,  1081,   262,  ..., 50257, 50257, 50257]])\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])\n",
            "<class 'torch.Tensor'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "469"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counter = 0\n",
        "for i, a in data:\n",
        "    counter += 1\n",
        "    if counter <= 1:\n",
        "        print(i)\n",
        "        print(type(i))\n",
        "        print(a)\n",
        "        print(type(a))\n",
        "\n",
        "counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fm_F-1MXoUe"
      },
      "source": [
        "### Load pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSDnf19QXoUe",
        "outputId": "1b3b8846-718b-4d67-c3c3-d1c751243e63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50261, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50261, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config = transformers.GPT2Config.from_pretrained(\"gpt2\")\n",
        "config.do_sample = config.task_specific_params['text-generation']['do_sample']\n",
        "config.max_length = config.task_specific_params['text-generation']['max_length']\n",
        "model = transformers.GPT2LMHeadModel.from_pretrained(\"gpt2\", config=config)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex5nw1oJYQpx",
        "outputId": "d717b873-d17a-4f93-90fe-d7d11668e806"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3F0udytjYUST"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt7xXSLpXoUf"
      },
      "source": [
        "### First test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uQvjlRZXXoUf"
      },
      "outputs": [],
      "source": [
        "# prompt = \"Create me an interactive story to calm me down.\"\n",
        "# encoded = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "# print(f\"Encoding: {encoded}\\n\")\n",
        "# res = tokenizer.decode(model.generate(encoded)[0])\n",
        "# print(f\"Prompt:\\n{prompt}\\n\\nResult:\\n{res}\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "z5jeBTWOXeyW"
      },
      "outputs": [],
      "source": [
        "def inference(prompt:str, model, tokenizer, device, padding, clear_output=True):\n",
        "    model.eval()\n",
        "\n",
        "    prompt = f\"<startofstring> {prompt} <bot>:\"\n",
        "    prompt = tokenizer(prompt, return_tensors=\"pt\", padding=padding)\n",
        "    X = prompt[\"input_ids\"].to(device)\n",
        "    a = prompt[\"attention_mask\"].to(device)\n",
        "    output = model.generate(X, attention_mask=a, pad_token_id=tokenizer.eos_token_id)\n",
        "    output = tokenizer.decode(output[0])\n",
        "\n",
        "    # clean output:\n",
        "    if clear_output:\n",
        "        if \"<bot>:\" in output:\n",
        "            output = output.split(\"<bot>:\")[1:]\n",
        "\n",
        "        if \"<endofstring>\" in output:\n",
        "            output = output.replace(\"<endofstring>\", \"\")\n",
        "\n",
        "    if type(output) == list and len(output) == 1:\n",
        "        output = output[0]\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSqQU8y1XmFZ",
        "outputId": "64fb6f04-0ddb-4d08-8639-8fec24d2f889"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 1024, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
              " '']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inference(prompt=\"Create me a unique interactive story to calm with the topic: Ocean.\", model=model, tokenizer=tokenizer,\n",
        "                                                        device=device, padding=\"max_length\", clear_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "1wIUfCozcxi5",
        "outputId": "c05d33c0-6931-4d88-e3be-5f3b086ceb94"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 1024, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<startofstring> Hey. <bot>:<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inference(prompt=\"Hey.\", model=model, tokenizer=tokenizer, device=device, padding=\"max_length\", clear_output=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0zGPe1pXoUf"
      },
      "source": [
        "### Fine Tune Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        },
        "id": "hqc6pXHvXoUf",
        "outputId": "232b281c-9f4d-4be9-e73a-c7d7e9e794a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/12, Training Loss: 1.5003, Steps: 469\n",
            "Epoch 2/12, Training Loss: 1.3575, Steps: 938\n",
            "Epoch 3/12, Training Loss: 1.2683, Steps: 1407\n",
            "Epoch 4/12, Training Loss: 1.2065, Steps: 1876\n",
            "Epoch 5/12, Training Loss: 1.1694, Steps: 2345\n",
            "Epoch 6/12, Training Loss: 1.1247, Steps: 2814\n",
            "Epoch 7/12, Training Loss: 1.0943, Steps: 3283\n",
            "Epoch 8/12, Training Loss: 1.0414, Steps: 3752\n",
            "Epoch 9/12, Training Loss: 1.0182, Steps: 4221\n",
            "Epoch 10/12, Training Loss: 0.9885, Steps: 4690\n",
            "Epoch 11/12, Training Loss: 0.9570, Steps: 5159\n",
            "Epoch 12/12, Training Loss: 0.9309, Steps: 5628\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1600x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "optimizer = Adam(model.parameters(), lr=1e-4)\n",
        "epochs = 12\n",
        "\n",
        "loss_hist = []\n",
        "steps = 0\n",
        "\n",
        "solutions = []\n",
        "solutions_cleared = []\n",
        "\n",
        "for cur_epoch in range(0, epochs):\n",
        "    model.train()\n",
        "    for input_ids, attention_mask in data:\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        # shift labels?\n",
        "        optimizer.zero_grad()\n",
        "        loss = model(input_ids, attention_mask=attention_mask, labels=input_ids).loss\n",
        "        loss_hist += [loss.item()]\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        steps += 1\n",
        "    torch.save(model.state_dict(), \"./model_state.pt\")\n",
        "    print(f'Epoch {cur_epoch+1}/{epochs}, Training Loss: {loss.item():.4f}, Steps: {steps}')\n",
        "    solutions += [inference(prompt=\"Create me a unique interactive story to calm with the topic: Ocean.\", model=model, tokenizer=tokenizer,\n",
        "                                                        device=device, padding=True, clear_output=False)]\n",
        "    solutions_cleared += [inference(prompt=\"Create me a unique interactive story to calm with the topic: Ocean.\", model=model, tokenizer=tokenizer,\n",
        "                                                        device=device, padding=True, clear_output=True)]\n",
        "\n",
        "# plot loss\n",
        "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
        "ax.plot(np.arange(len(loss_hist)), loss_hist, label='Loss')\n",
        "ax.set_xlabel('Learning progress')\n",
        "ax.set_ylabel('Loss (normalized mean absolute error)')\n",
        "ax.set_title('Loss over time')\n",
        "ax.legend()\n",
        "ax.grid()\n",
        "\n",
        "# save step solution-predictions:\n",
        "with open(\"./result_per_epoch.txt\", \"w\") as f:\n",
        "    res = \"\"\n",
        "    for i, cur_res in enumerate(solutions, start=1):\n",
        "        res += f\"\\n{'-'*16}\\n{i:02d}. Epoch:\\n{cur_res}\"\n",
        "    f.write(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnfKTdk5XoUf"
      },
      "source": [
        "### Save model\n",
        "\n",
        "-> Propably save the model in a extra repository/branch and provide it as python module<br>\n",
        "-> Is model very big?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8M7Q0aUXoUf"
      },
      "source": [
        "save only weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "H9QFdpqfXoUf"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), MODEL_WEIGHT_PATH)\n",
        "\n",
        "# loading\n",
        "# config = transformers.GPT2Config.from_pretrained(\"gpt2\")\n",
        "# config.do_sample = config.task_specific_params['text-generation']['do_sample']\n",
        "# config.max_length = config.task_specific_params['text-generation']['max_length']\n",
        "# model = transformers.GPT2LMHeadModel.from_pretrained(\"gpt2\", config=config)\n",
        "# model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# model.load_state_dict(torch.load(MODEL_WEIGHT_PATH))\n",
        "# model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNbmw4pDXoUf"
      },
      "source": [
        "save whole model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "C6gPFu3RXoUf"
      },
      "outputs": [],
      "source": [
        "torch.save(model, MODEL_PATH)\n",
        "\n",
        "# loading\n",
        "# model = torch.load(MODEL_PATH)\n",
        "# model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrC-VrsWXoUf"
      },
      "source": [
        "save as ONNX\n",
        "\n",
        "see here -> https://onnxruntime.ai/docs/get-started/with-python.html<br>\n",
        "or here -> https://pytorch.org/tutorials/beginner/onnx/export_simple_model_to_onnx_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GP4pPCQvXoUg"
      },
      "outputs": [],
      "source": [
        "def get_example_data():\n",
        "    for i, a in data:\n",
        "        return i, a\n",
        "i, a = get_example_data()\n",
        "\n",
        "i = i.to(device)\n",
        "\n",
        "# or:\n",
        "\n",
        "# text = \"Text from the news article\"\n",
        "# text = torch.tensor(text_pipeline(text))\n",
        "# offsets = torch.tensor([0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV_FDMLIJIeD",
        "outputId": "076f7a72-2905-43c1-903e-3ea02cca7800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.15.0\n"
          ]
        }
      ],
      "source": [
        "#!pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "cH37ZEvaXoUg",
        "outputId": "3ea82091-55d0-4556-afcc-d41a82ec485d"
      },
      "outputs": [
        {
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-ee98e6a0ffa7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m torch.onnx.export(model,                     # model being run\n\u001b[0m\u001b[1;32m      2\u001b[0m                   \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m                    \u001b[0;31m# model input (or a tuple for multiple inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mONNX_PATH\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0;31m# where to save the model (can be a file or file-like object)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mexport_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;31m# store the trained parameter weights inside the model file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \u001b[0mopset_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# the ONNX version to export the model to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \"\"\"\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m     _export(\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0m_validate_dynamic_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1596\u001b[0;31m             graph, params_dict, torch_out = _model_to_graph(\n\u001b[0m\u001b[1;32m   1597\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pre_trace_quant_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_jit_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_named_param_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_trace_and_get_graph_from_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m     \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_onnx_lint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0mprev_autocast_cache_enabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_autocast_cache_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_autocast_cache_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m     trace_graph, torch_out, inputs_states = torch.jit._get_trace_graph(\n\u001b[0m\u001b[1;32m    916\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1283\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m     outs = ONNXTracedModule(\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m     )(*args, **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         graph, out = torch._C._create_graph_by_tracing(\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0min_vars\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1509\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1075\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1509\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    886\u001b[0m                 )\n\u001b[1;32m    887\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    889\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1509\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1509\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1509\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.044715\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 59.06 MiB is free. Process 147202 has 14.69 GiB memory in use. Of the allocated memory 13.74 GiB is allocated by PyTorch, and 832.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "torch.onnx.export(model,                     # model being run\n",
        "                  i,                    # model input (or a tuple for multiple inputs)\n",
        "                  ONNX_PATH,                 # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=10,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output']  # the model's output names\n",
        "                    )\n",
        "\n",
        "# loading\n",
        "# import onnx\n",
        "\n",
        "# onnx_model = onnx.load(ONNX_PATH)\n",
        "# onnx.checker.check_model(onnx_model)\n",
        "\n",
        "# import onnxruntime as ort\n",
        "# import numpy as np\n",
        "# ort_sess = ort.InferenceSession('ag_news_model.onnx')\n",
        "# outputs = ort_sess.run(None, {'input': text.numpy(),\n",
        "#                             'offsets':  torch.tensor([0]).numpy()})\n",
        "# # Print Result\n",
        "# result = outputs[0].argmax(axis=1)+1\n",
        "# print(\"This is a %s news\" %ag_news_label[result[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PDOp4CVXoUg"
      },
      "source": [
        "### Use the model\n",
        "\n",
        "-> Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_sentence = \"Create me a unique interactive story to calm with the topic:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-YmHF_1UU1jF"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'inference' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     10\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_sentence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBot:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43minference\u001b[49m(user_input, model\u001b[38;5;241m=\u001b[39mmodel, device\u001b[38;5;241m=\u001b[39mdevice, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, clear_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m     12\u001b[0m loop \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'inference' is not defined"
          ]
        }
      ],
      "source": [
        "loop = 0\n",
        "while True:\n",
        "    user_input = input()\n",
        "    if user_input.lower() in [\"q\", \"quit\", \"e\", \"exit\", \"\", \"x\"]:\n",
        "        print(\"See you later! I hope you had fun ^^\")\n",
        "        break\n",
        "    elif user_input in [\"restart\", \"new\"]:\n",
        "        loop = 0\n",
        "    if loop == 0:\n",
        "        user_input = f\"{start_sentence} {user_input}\"\n",
        "    print(\"Bot:\", inference(user_input, model=model, device=device, tokenizer=tokenizer, padding=\"max_length\", clear_output=False))\n",
        "    loop += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mX9kJzSXoUg"
      },
      "outputs": [],
      "source": [
        "# def infer(inp):\n",
        "#   inp = \" \" + inp + \" : \"\n",
        "#   inp = tokenizer(inp, return_tensors=\"pt\")\n",
        "#   X = inp[\"input_ids\"].to(device)  # Use .to(device) method to move the tensor to the specified device\n",
        "#   a = inp[\"attention_mask\"].to(device)  # Use .to(device) method here as well\n",
        "\n",
        "#   output = model.generate(X, attention_mask=a, max_length=100, num_return_sequences=1)\n",
        "\n",
        "#   output = tokenizer.decode(output[0])\n",
        "\n",
        "#   return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### Ressources:\n",
        "\n",
        "- https://www.toolify.ai/ai-news/finetuning-gpt2-for-conversational-chatbots-10476\n",
        "- https://huggingface.co/docs/transformers/model_doc/gpt2\n",
        "- [PyTorch kompakt](https://www.thalia.de/shop/home/artikeldetails/A1062166688)\n",
        "- https://pytorch.org/tutorials/beginner/chatbot_tutorial.html\n",
        "- https://github.com/itsuncheng/fine-tuning-GPT2/tree/master\n",
        "\n",
        "<br>\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
