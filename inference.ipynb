{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "### Your interactive story\n",
    "\n",
    "-> Try out station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.1\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (23.3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: tsfresh 0.18.0 has a non-standard dependency specifier matrixprofile>=1.1.10<2.0.0. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of tsfresh or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.20.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: tsfresh 0.18.0 has a non-standard dependency specifier matrixprofile>=1.1.10<2.0.0. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of tsfresh or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "DEPRECATION: tsfresh 0.18.0 has a non-standard dependency specifier matrixprofile>=1.1.10<2.0.0. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of tsfresh or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.10.7)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (1.8)\n",
      "Requirement already satisfied: networkx in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.36.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (3.10.7)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2021.7.6)\n",
      "Requirement already satisfied: requests in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2.25.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: tsfresh 0.18.0 has a non-standard dependency specifier matrixprofile>=1.1.10<2.0.0. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of tsfresh or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (4.62.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\tobia\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tobia\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2020.12.5)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install numpy\n",
    "!python -m pip install torch\n",
    "!python -m pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH = 1024\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"gpt2\", max_length=MAX_LENGTH)\n",
    "tokenizer.add_special_tokens({  \"pad_token\": \"<pad>\",\n",
    "                                \"bos_token\": \"<start>\",\n",
    "                                \"eos_token\": \"<end>\"})\n",
    "tokenizer.add_tokens([\"<bot>:\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "# loading\n",
    "#config = transformers.GPT2Config.from_pretrained(\"gpt2\")\n",
    "#config.max_length = 883\n",
    "model = transformers.GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(\"./model/V5/model_state_V5_6.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [9288, 27, 13645, 29, 50257, 50257], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tokenizer(\"test<bot><pad><pad>\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(prompt:str, model, tokenizer, device, padding, clear_output=True):\n",
    "    model.eval()\n",
    "    prompt = f\"{prompt}<bot>\"\n",
    "    prompt = tokenizer(prompt, return_tensors=\"pt\", padding=padding)\n",
    "    X = prompt[\"input_ids\"].to(device)\n",
    "    a = prompt[\"attention_mask\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(X, attention_mask=a, pad_token_id=tokenizer.pad_token_id, \n",
    "                                                        do_sample=True, max_length=MAX_LENGTH)\n",
    "\n",
    "    if clear_output:\n",
    "        output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    else:\n",
    "        output = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "\n",
    "    if type(output) == list and len(output) == 1:\n",
    "        output = output[0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Try out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey, I'm feeling not so good.<bot>I'm sorry to hear that. What's going on?I've been feeling really overwhelmed lately with everything going on in my life.I understand. It's tough when everything seems to pile up at once. Can you tell me a little more about what's been happening?Well, I have been dealing with a lot of stress at work, and it's starting to take a toll on my mental health. I've also been having trouble sleeping and I feel like I'm constantly on edge.<bot>:It sounds like you're dealing with a lot right now. Have you tried any strategies to manage your stress levels?ongyang ideology\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = inference(prompt=\"Hey, I'm feeling not so good.\", model=model, tokenizer=tokenizer,\n",
    "                                                        device=device, padding=True, clear_output=True)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "c:\\Users\\tobia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\generation\\utils.py:1363: UserWarning: Input length of input_ids is 1024, but `max_length` is set to 1024. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: hey<bot>\n",
      "See you later! I hope you had fun ^^\n"
     ]
    }
   ],
   "source": [
    "loop = 0\n",
    "while True:\n",
    "    user_input = input()\n",
    "    if user_input.lower() in [\"q\", \"quit\", \"e\", \"exit\", \"\", \"x\"]:\n",
    "        print(\"See you later! I hope you had fun ^^\")\n",
    "        break\n",
    "    elif user_input in [\"restart\", \"new\"]:\n",
    "        loop = 0\n",
    "\n",
    "    print(\"Bot:\", inference(user_input, model=model, device=device, tokenizer=tokenizer, padding=True, clear_output=True))\n",
    "    loop += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
